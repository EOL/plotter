#!/bin/bash

# Split a single .csv file foo.csv into multiple smaller .csv files
# ("chunks"), all stored in directory foo.csv.chunks together.

# The number of records per chunk is currently fixed at 100000...

set -e
FILE="$1"
CHUNK=100000
DIR="$FILE".chunks

if [ ! -r "$FILE" ]; then
  if [ ! -d "$DIR" ]; then
    echo "no such file: $FILE"
    exit 1
  else
    exit 0
  fi
elif [ `wc -l $FILE | (read x y; echo $x)` -gt 1 ]; then
  rm -rf "$DIR"
  mkdir -p "$DIR"
  tail --lines=+2 "$FILE" | split --lines=$CHUNK - "$DIR"/
  for f in "$DIR"/*; do
    echo "adding header line to $f.csv"
    (head --lines=1 "$FILE"; cat "$f") >"$f".csv
    rm "$f"
  done
  rm "$FILE"
fi
